{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a34609-c870-4a4a-8665-510cb9b56fbf",
   "metadata": {},
   "source": [
    "# Activity Recognition on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f1760-d610-4971-ae8e-780551a12b04",
   "metadata": {},
   "source": [
    "To reproduce this example, run the cells below. Note that running some of the cells will call SageMaker APIs, such as the ones for training and deployment, which may incur charges. Be sure to cleanup all resources at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3d839-ea8b-485e-8b15-b34d5d937d1b",
   "metadata": {},
   "source": [
    "## Prepare libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99ea029f-1764-49f9-a085-ffeec82f331a",
   "metadata": {},
   "source": [
    "We will be using the SageMaker SDK to interact with the SageMaker service. We will use version 2.181.0 of the SDK. We will also use the numpy library for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd9cdf-43e7-49c0-9248-6776d3f8bd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39417be3-3ab2-425c-bc4c-aa72946b94f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from numpy.random import rand\n",
    "from numpy import argmax, float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128477c-7cac-4fd7-85b2-7c07480106b1",
   "metadata": {},
   "source": [
    "We setup SageMaker constructs including a SageMaker session, execution role, and default bucket for data and model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccfca3-42b8-4403-940f-88c4af2fc3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = Session()\n",
    "role = get_execution_role()\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf8dd3-70aa-4ec1-b59c-b1d2b982b245",
   "metadata": {},
   "source": [
    "## Prepare and save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baac532-d775-4e91-9f2a-73c2d1a57c11",
   "metadata": {},
   "source": [
    "### Download data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f9191-1988-4914-b028-829c8e585ae1",
   "metadata": {},
   "source": [
    "We first download the data from the UCI machine learning repository and unzip the dataset into the data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68c577-ab81-4e0e-92f2-7630c53f9696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -q -O uci_har_dataset.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
    "!unzip -q uci_har_dataset.zip && mv 'UCI HAR Dataset' data\n",
    "!rm uci_har_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d9edb-f1c3-4421-bd9b-18f91b3ff5ec",
   "metadata": {},
   "source": [
    "### Upload data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b37d2f-e1f3-4221-9f32-4d7fa38487db",
   "metadata": {},
   "source": [
    "We'll upload the data to the default SageMaker bucket in our Region. Feel free to change the bucket to a custom bucket in your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1ed61-f0aa-45b6-b345-cf770d0b9fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_data_location = f's3://{bucket}/activity-recognition/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ba679-5570-4fd9-950c-ebe40729a980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S3Uploader.upload(\n",
    "    local_path = 'data/', \n",
    "    desired_s3_uri = s3_data_location, \n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7078ca1-0283-4074-acc5-0816191024d7",
   "metadata": {},
   "source": [
    "## Create training script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac1586-6f1d-4621-8c76-0049181be7e4",
   "metadata": {},
   "source": [
    "With SageMaker script mode, we provide a training script and use a prebuilt framework container to run the script. In this case, we will write a PyTorch script for PyTorch version 1.13.1. We will split our model definition and our training script into two different files and put them in the same directory (sagemaker_scripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016d2c1-f3cc-4b09-93b7-109265c1b489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir sagemaker_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07125510-4762-4568-9567-7bed48aa6887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile sagemaker_scripts/model.py\n",
    "\n",
    "\"\"\" Model definition \"\"\"\n",
    "from torch.nn import (\n",
    "    Dropout,\n",
    "    Linear,\n",
    "    LSTM,\n",
    "    Module,\n",
    "    ReLU,\n",
    "    Softmax\n",
    ")\n",
    "\n",
    "class LSTMClassifier(Module):\n",
    "    \"\"\"\n",
    "    A PyTorch LSTM implementation.\n",
    "\n",
    "    Methods:\n",
    "        __init__(self, input_dim, hidden_dim, output_dim):\n",
    "            Initializes the neural network.\n",
    "\n",
    "        forward(self, x):\n",
    "            Defines the forward pass of the neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the neural network module.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Number of input features.\n",
    "            hidden_dim (int): Number of hidden nodes in the neural network.\n",
    "            output_dim (int): Number of output nodes in the neural network.\n",
    "        \"\"\"\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.relu = ReLU()\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.fc = Linear(hidden_dim, output_dim)\n",
    "        self.softmax = Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the PyTorch module.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to the module.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after applying the forward computation.\n",
    "        \"\"\"\n",
    "        lstm_output, _ = self.lstm(x)\n",
    "        x = lstm_output[:, -1, :] # only take the last timestamp's state (since LSTM is recursive)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f10105e0-b2e9-4a7d-accf-e2f7c7a04325",
   "metadata": {},
   "source": [
    "The below script is a fairly standard PyTorch training script. \n",
    "\n",
    "To load the data into memory, we use several functions specific to the file structure of this dataset. These functions were derived from [this](https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/) tutorial. \n",
    "\n",
    "For the model, we use an LSTM plus a linear output layer equal to the number of activities we want to predict (in this case, 6). We use softmax as our final activation to get the probabilities of each class from the network. We use categorical cross entropy for the loss function, the Adam optimizer, and a learning rate scheduler that halves the learning rate every 10 epochs. \n",
    "\n",
    "To make the script play nicely with SageMaker we parse arguments such as batch size, learning rate, and data location that get passed to our script during invocation. We also make sure to save our model in the ```/opt/ml/model``` directory. This is the directory expected by SageMaker and allows SageMaker to copy our model artifacts to S3 upon completion of the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67594e78-4363-450b-9a6a-12cb3c24bf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sagemaker_scripts/torch_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sagemaker_scripts/torch_train.py\n",
    "\n",
    "\"\"\" SageMaker Training Script \"\"\"\n",
    "\n",
    "# Sagemaker imports\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "from numpy import (\n",
    "    arange,\n",
    "    argmax,\n",
    "    count_nonzero,\n",
    "    dstack,\n",
    "    zeros\n",
    ")\n",
    "from pandas import read_csv\n",
    "from torch import (\n",
    "    cuda as torch_cuda,\n",
    "    device as torch_device,\n",
    "    no_grad as torch_no_grad,\n",
    "    Tensor\n",
    ")\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.jit import (\n",
    "    save as torch_jit_save,\n",
    "    script as torch_jit_script\n",
    ")\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model import LSTMClassifier\n",
    "\n",
    "# setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def load_file(filepath):\n",
    "    \"\"\"\n",
    "    Loads a single file as a numpy array\n",
    "\n",
    "    Args:\n",
    "        filepath (string): Local path to file\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Array containing data from file\n",
    "    \"\"\"\n",
    "    print('Reading from file: ', filepath)\n",
    "    df = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return df.values\n",
    "\n",
    "def load_file_group(filenames, prefix=''):\n",
    "    \"\"\"\n",
    "    Loads a list of files and return as a 3d numpy array\n",
    "\n",
    "    Args:\n",
    "        filenames (list of strings): List of filenames containing input data\n",
    "        prefix (string): Optional prefix for local filepath\n",
    "\n",
    "    Returns:\n",
    "        numpy array: 3d numpy array containing data from files\n",
    "    \"\"\"\n",
    "    data_group = []\n",
    "    for filename in filenames:\n",
    "        data = load_file(prefix + filename)\n",
    "        data_group.append(data)\n",
    "\n",
    "    return dstack(data_group)\n",
    "\n",
    "def load_dataset_type(dataset_type, prefix=''):\n",
    "    \"\"\"\n",
    "    Loads a dataset type, such as train or test\n",
    "\n",
    "    Args:\n",
    "        dataset_type (string): Group name such as 'train' or 'test'\n",
    "        prefix (string): Optional prefix for local filepath\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Features\n",
    "        numpy array: Labels\n",
    "    \"\"\"\n",
    "    data_folder_path = prefix + dataset_type + '/Inertial Signals/'\n",
    "    filenames = []\n",
    "    for signal_type in ['total_acc', 'body_acc', 'body_gyro']:\n",
    "        for axis in ['x', 'y', 'z']:\n",
    "            filenames.append(f'{signal_type}_{axis}_{dataset_type}.txt') \n",
    "\n",
    "    X = load_file_group(filenames = filenames, prefix = data_folder_path)\n",
    "    y = load_file(prefix + dataset_type + '/y_'+dataset_type+'.txt')\n",
    "    return X, y\n",
    "\n",
    "def one_hot_encode(inputs):\n",
    "    \"\"\"\n",
    "    One hot encodes a Numpy array\n",
    "\n",
    "    Args:\n",
    "        inputs (numpy array): 1d numpy array containing class indices\n",
    "\n",
    "    Returns:\n",
    "        numpy array: 2d numpy array with one hot encoded class indices\n",
    "    \"\"\"\n",
    "    outputs = zeros((inputs.size, inputs.max() + 1))\n",
    "    outputs[arange(inputs.size), inputs] = 1\n",
    "    return outputs\n",
    "\n",
    "def load_dataset(prefix=''):\n",
    "    \"\"\"\n",
    "    Loads the dataset\n",
    "\n",
    "    Args:\n",
    "        prefix (string): Optional prefix for local filepath\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Features for train dataset\n",
    "        numpy array: Labels for train dataset\n",
    "        numpy array: Features for test dataset\n",
    "        numpy array: Labels for test dataset\n",
    "    \"\"\"\n",
    "    # load train dataset\n",
    "    train_X, train_y = load_dataset_type(dataset_type = 'train', prefix = prefix + '/')\n",
    "    # load test dataset\n",
    "    test_X, test_y = load_dataset_type(dataset_type = 'test', prefix = prefix + '/')\n",
    "\n",
    "    # offset class values to start at zero\n",
    "    train_y = train_y - 1\n",
    "    test_y = test_y - 1\n",
    "\n",
    "    # one-hot encode labels\n",
    "    train_y = train_y.reshape(len(train_y)) # array of single-label arrays -> array of labels\n",
    "    test_y = test_y.reshape(len(test_y)) \n",
    "    train_y = one_hot_encode(train_y) # one hot encode train labels for neural network\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "def train(model, train_X, train_y, test_X, test_y, num_epochs = 20, batch_size = 64, learning_rate = 0.01):\n",
    "    \"\"\"\n",
    "    Trains the model on the given dataset and evaluates model after each epoch\n",
    "\n",
    "    Args:\n",
    "        model (PyTorch NN module): Model to be trained\n",
    "        train_X (numpy array): Features for train dataset\n",
    "        train_y (numpy array): Labels for train dataset\n",
    "        test_X (numpy array): Features for test dataset\n",
    "        test_y (numpy array): Labels for test dataset\n",
    "        num_epochs (int): Optional, specifies number of epochs to train for, default=20\n",
    "        batch_size (int): Optional, specifies batch size for training, default=64\n",
    "        learning_rate (float): Optional, specifies initial learning rate for training, default=0.01\n",
    "\n",
    "    Returns:\n",
    "        PyTorch NN module: Trained model\n",
    "    \"\"\"\n",
    "    device = torch_device('cuda' if torch_cuda.is_available() else 'cpu')\n",
    "    model.to(device) # pass model to GPU if present\n",
    "\n",
    "    train_X_tensor = Tensor(train_X)\n",
    "    train_y_tensor = Tensor(train_y)\n",
    "    train_dataset = TensorDataset(train_X_tensor, train_y_tensor) \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size = batch_size)\n",
    "\n",
    "    cat_loss = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch, labels in train_dataloader:\n",
    "            batch, labels = batch.to(device), labels.to(device) # pass data to GPU if present\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = cat_loss(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "  \n",
    "        curr_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step() # update the learning rate\n",
    "\n",
    "        # evaluate after each epoch\n",
    "        model.eval()\n",
    "        with torch_no_grad():\n",
    "            test_X_tensor = Tensor(test_X)\n",
    "            test_X_tensor = test_X_tensor.to(device)\n",
    "            test_outputs = model(test_X_tensor)\n",
    "            predictions = argmax(test_outputs.cpu().detach().numpy(), axis=-1)\n",
    "            accuracy = count_nonzero(predictions == test_y) / len(test_y)\n",
    "\n",
    "        logging.info(f'Epoch {i + 1} of {num_epochs}, Loss: {loss.item()}, Test Accuracy: {accuracy}, LR: {curr_lr}')\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data', type=str, default=os.environ.get('SM_CHANNEL_DATA')) # usually this is split into train and test\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--epochs', type=int, default=20)\n",
    "    parser.add_argument('--learning-rate', type=float, default=0.01)\n",
    "    parser.add_argument('--batch-size', type=int, default=64)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # load data\n",
    "    train_X, train_y, test_X, test_y = load_dataset(prefix=args.data)\n",
    "    n_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[2], train_y.shape[1]\n",
    "\n",
    "    # fit model\n",
    "    model = LSTMClassifier(n_features, 100, n_outputs)\n",
    "    trained_model = train(model, train_X, train_y, test_X, test_y, args.epochs, args.batch_size, args.learning_rate)\n",
    "\n",
    "    # pickle and save the model\n",
    "    model_path = os.path.join('/opt/ml/model', 'model.pt')\n",
    "    trained_model = torch_jit_script(trained_model)\n",
    "    torch_jit_save(trained_model, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841596f-0fa0-4f7d-870e-ae21ce9bcb00",
   "metadata": {},
   "source": [
    "## Create SageMaker Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b3d9b-98b1-42d1-aaf0-bf3b7b9be6a1",
   "metadata": {},
   "source": [
    "Next we will define our hyperparameters and SageMaker Estimator. As mentioned earlier, we will use the PyTorch framework container with PyTorch version 1.13.1 and Python3.9. We provide our main training script as the ```entry_point``` parameter and the directory containing all of our files (including a requirements.txt if we needed to provide one) in the ```source_dir``` parameter. \n",
    "\n",
    "We will use a single ml.g5.xlarge instance for this training job. The ml.g5.xlarge instance has 4 vCPU, 16 GB memory, 1 NVIDIA A10G GPU, and 24 GB GPU memory. We will also specify ```keep_alive_period_in_seconds``` to make use of SageMaker Warm Pools, so that subsequent training runs start faster. Delete this parameter if you are only running a single training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59599ed9-c462-4083-85b5-f1b0d169f1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'epochs': 50, \n",
    "    'batch-size': 64, \n",
    "    'learning-rate': 0.02\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a79bfe-ed42-4f41-8dce-c258829094f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_estimator = PyTorch(\n",
    "    entry_point='torch_train.py',\n",
    "    source_dir='sagemaker_scripts',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    py_version='py39',\n",
    "    framework_version='1.13.1',\n",
    "    output_path=f's3://{bucket}/activity-recognition/outputs/',\n",
    "    hyperparameters=hyperparameters,\n",
    "    keep_alive_period_in_seconds=900 # warm pool configuration for repeated training (15 mins)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56892a9-2fd2-4315-8b69-a8405891fa73",
   "metadata": {},
   "source": [
    "Now we will call fit() on our Estimator and pass in our input data to start the training job. This process will take a few minutes to complete. We should see from the logs that the model reaches ~88% accuracy. If you do not see that performance, you may need to change the learning rate or number of epochs in the hyperparameter dictionary above.\n",
    "\n",
    "Note: It is a common pattern to first prepare that data (preprocess and split into train/val/test for example) before passing it to the training job and provide the fit() method with multiple data channels (i.e. train and test). However, in this example, the data is already processed and split by folders. Therefore, we will just pass the data in a single channel called 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3e86e-5f44-4e49-a16b-ddc8cb5e295c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_estimator.fit({\"data\": s3_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa3e01-6c21-4773-9090-c833964b9734",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef2d86-4817-414d-8af5-89a85b5f16b1",
   "metadata": {},
   "source": [
    "To deploy our model, we will simply call the deploy() function on our Estimator. For deployment, we will use a CPU instance, the ml.m5.4xlarge with 16 vCPU and 64 GB memory. Feel free to change this to a different instance type, depending on your performance and cost requirements (make sure to pick an instance size that has enough memory of GPU memory to fit the model). This process will take a few minutes to complete. \n",
    "\n",
    "Note: If we have run the training job in the past but loss the ```torch_estimator``` variable (this can sometimes happen if the kernel is restarted), we could create a SageMaker Model object using the model artifact location in S3 and calling deploy() on the Model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa70544-a4f9-4bf7-a90c-7ed9f59bb7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = torch_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.4xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53edc7-fb51-4324-9318-7be4d57d0195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_inputs = rand(1, 128, 9).astype(float32)\n",
    "\n",
    "result = predictor.predict(dummy_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c4d336e-242c-4492-96a9-0f8de7536118",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.02133990e-08, 1.16042474e-06, 9.99998808e-01, 5.32531297e-10,\n",
       "        9.05011201e-14, 1.52982560e-09]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce14669a-a709-4e7e-b763-afb7e3296e7f",
   "metadata": {},
   "source": [
    "We have 6 predictions, one for each class. In order to get the class label, we will take the index with the highest predicted probability and map it to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5633940-fa99-42f6-87eb-740b7c432b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the activity with the highest predicted probability\n",
    "activity_index = argmax(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58baf456-9dab-4177-b7fc-fbb87188d8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get class labels\n",
    "activities = []\n",
    "with open('data/activity_labels.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        activities.append(line.rstrip('\\n')[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77638edd-0901-4e4e-8b61-9f3e0122d9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted activity:  WALKING_DOWNSTAIRS\n"
     ]
    }
   ],
   "source": [
    "print('Predicted activity: ', activities[activity_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230da696-cf96-4fdc-9890-128d2db2e48a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e3fd3-0856-4592-a743-60527f3ddee8",
   "metadata": {},
   "source": [
    "Make sure to delete the resources created by this notebook to prevent unnecessary charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b5696-fba9-48b8-b29b-022ac1878438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
